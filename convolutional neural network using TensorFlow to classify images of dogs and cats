import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Parameters
batch_size = 32
image_size = (150, 150)

# ImageDataGenerator for training and validation datasets
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

# Load the training and validation datasets
train_data = train_datagen.flow_from_directory('/path/to/train/',
                                               target_size=image_size,
                                               batch_size=batch_size,
                                               class_mode='binary')

val_data = val_datagen.flow_from_directory('/path/to/val/',
                                           target_size=image_size,
                                           batch_size=batch_size,
                                           class_mode='binary')

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.Adam(),
              metrics=['accuracy'])

# Train the model
history = model.fit(train_data,
                    epochs=10,
                    validation_data=val_data)

# Evaluate the model on the test dataset
test_loss, test_acc = model.evaluate(val_data)
print('Test accuracy:', test_acc)
